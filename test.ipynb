{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ.get(\"PYTORCH_ENABLE_MPS_FALLBACK\")='1'\n",
      "DEVICE=device(type='mps')\n",
      "PRETRAINED_MODEL='gpt2-small'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lihenan/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test model generate: The Space Needle is in the city of Sedro Renica. It holds what must have\n",
      "print model structure HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x TransformerBlock(\n",
      "      (ln1): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNormPre(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from circuitsvis.attention import attention_heads\n",
    "from fancy_einsum import einsum\n",
    "from functools import partial\n",
    "from IPython.display import HTML, IFrame\n",
    "from jaxtyping import Float\n",
    "from os import environ\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from typing import List, Optional, Union\n",
    "import circuitsvis as cv\n",
    "import dotenv\n",
    "import einops\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from utils import imshow, line, scatter\n",
    "\n",
    "dotenv.load_dotenv('.env', override=True)\n",
    "print(f'{environ.get(\"PYTORCH_ENABLE_MPS_FALLBACK\")=}')\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "DEVICE = utils.get_device()\n",
    "print(f'{DEVICE=}')\n",
    "\n",
    "PRETRAINED_MODEL = 'gpt2-small'  # gpt2-small or gpt2-medium\n",
    "print(f'{PRETRAINED_MODEL=}')\n",
    "\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\n",
    "    PRETRAINED_MODEL, center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True, device=DEVICE)\n",
    "\n",
    "print(\"test model generate:\", model.generate(\n",
    "    \"The Space Needle is in the city of\"))\n",
    "\n",
    "print(\"print model structure\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123+456=|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', '+', '456', '=']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1025</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.06</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1025\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m5.06\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 10.69 Prob:  3.82% Token: |123|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.65</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.37</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m60\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.65\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.37\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.48 Prob:  2.30% Token: |\n",
      "|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1025</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m1025\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m60\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=| 123+456=|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', ' 123', '+', '456', '=']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">439</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.77</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m439\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m5.77\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.32 Prob:  7.90% Token: |123|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.18</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.32</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m62\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.18\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.32\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.56 Prob:  3.41% Token: |\n",
      "|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">439</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m439\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m62\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=| 123 +456=|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', ' 123', ' +', '456', '=']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.74</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m43\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m7.74\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 10.62 Prob:  4.43% Token: |123|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.00</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.61</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m24\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m10.00\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.61\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 12.00 Prob:  4.49% Token: | +|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m43\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m24\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=| 123 + 456=|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', ' 123', ' +', ' 4', '56', '=']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">        Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.55</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.70</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m        Logit:  \u001b[0m\u001b[1;36m8.55\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.70\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit:  9.53 Prob:  1.87% Token: |\n",
      "|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.58</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.38</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m39\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m8.58\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.38\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.43 Prob:  6.52% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m39\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=| 123 + 456 =|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', ' 123', ' +', ' 4', '56', ' =']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.99</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.59</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m10.99\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m1.59\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.84 Prob:  3.70% Token: | 1|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.41</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.61</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m21\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.41\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.61\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 12.16 Prob:  9.45% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m21\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=| 123 + 456 = |, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', ' 123', ' +', ' 4', '56', ' =', ' ']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2864</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.22</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m2864\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m3.22\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 13.40 Prob: 11.12% Token: | |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.81</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.50</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m26\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m8.81\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.47 Prob:  7.16% Token: | +|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2864</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m2864\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m26\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123 +456=|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', ' +', '456', '=']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.49</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.22</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m55\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m7.49\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.22\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 10.12 Prob:  3.07% Token: |123|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.20</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.65</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m26\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m10.20\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.65\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.82 Prob:  3.29% Token: | +|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m55\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m26\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123 + 456=|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', ' +', ' 4', '56', '=']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.43</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.70</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m8.43\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.70\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit:  9.51 Prob:  2.05% Token: |\n",
      "|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.54</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.34</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m45\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m8.54\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.34\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.67 Prob:  7.86% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m45\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123 + 456 =|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', ' +', ' 4', '56', ' =']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.39</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.09</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m11.39\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m2.09\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.95 Prob:  3.67% Token: | 1|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.31</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.51</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m27\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.31\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.51\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 12.48 Prob: 12.00% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m27\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123+ 456=|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', '+', ' 4', '56', '=']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.16</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m47\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m7.16\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.24\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit:  9.26 Prob:  1.95% Token: |\n",
      "|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.98</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m75\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m7.98\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.24\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.07 Prob:  5.20% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m47\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m75\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123+ 456 =|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', '+', ' 4', '56', ' =']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">        Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.91</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.63</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m        Logit:  \u001b[0m\u001b[1;36m9.91\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m1.63\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 10.61 Prob:  3.29% Token: | 1|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.25</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.26</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m80\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m8.25\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.26\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.77 Prob:  8.72% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m80\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123+ 456 = |, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', '+', ' 4', '56', ' =', ' ']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3658</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.98</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m3658\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m2.98\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 13.57 Prob: 11.60% Token: |????|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.60</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.20</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m99\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m7.60\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 10.90 Prob:  5.46% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3658</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m3658\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m99\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123+456 =|, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', '+', '456', ' =']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.14</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.69</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m15\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.14\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.69\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 12.06 Prob: 12.69% Token: | 123|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.82</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.46</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m56\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.82\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.46\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 11.51 Prob:  2.49% Token: |\n",
      "|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m56\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123+456 = |, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', '+', '456', ' =', ' ']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6643</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.42</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m6643\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m2.42\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 13.69 Prob:  8.38% Token: |【|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.17</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.42</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m56\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.17\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.42\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 10.64 Prob:  1.83% Token: |\n",
      "|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6643</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m6643\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m56\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=|123+456= |, answer=| 579|\n",
      "Tokenized prompt: ['<|endoftext|>', '123', '+', '456', '=', ' ']\n",
      "Tokenized answer: [' 5', '79']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7019</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.36</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m7019\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m2.36\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 14.04 Prob: 12.58% Token: |irc|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.91</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.42</span><span style=\"font-weight: bold\">% Token: |</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span><span style=\"font-weight: bold\">|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m45\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m8.91\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.42\u001b[0m\u001b[1m% Token: |\u001b[0m\u001b[1;36m79\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 10.36 Prob:  1.80% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' 5'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7019</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'79'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' 5'\u001b[0m, \u001b[1;36m7019\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'79'\u001b[0m, \u001b[1;36m45\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"123+456=\",\n",
    "    \" 123+456=\",\n",
    "    \" 123 +456=\",\n",
    "    \" 123 + 456=\",\n",
    "    \" 123 + 456 =\",\n",
    "    \" 123 + 456 = \",\n",
    "    \"123 +456=\",\n",
    "    \"123 + 456=\",\n",
    "    \"123 + 456 =\",\n",
    "    \"123+ 456=\",\n",
    "    \"123+ 456 =\",\n",
    "    \"123+ 456 = \",\n",
    "    \"123+456 =\",\n",
    "    \"123+456 = \",\n",
    "    \"123+456= \",\n",
    "]\n",
    "answers = [  # each answer contains 2 tokens\n",
    "    \" 579\",\n",
    "]\n",
    "\n",
    "\n",
    "# utils.test_prompt(prompt='123+123=', answer='579', model=model,\n",
    "#                   prepend_bos=True, prepend_space_to_answer=False, print_details=False)\n",
    "\n",
    "for p in prompts:\n",
    "    for a in answers:\n",
    "        print(f\"prompt=|{p}|, answer=|{a}|\")\n",
    "        utils.test_prompt(prompt=p, answer=a, model=model, top_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "prompt=|123 + 456 =|, answer=| 579|\n",
    "Tokenized prompt: ['<|endoftext|>', '123', ' +', ' 4', '56', ' =']\n",
    "Tokenized answer: [' 5', '79']\n",
    "Performance on answer token:\n",
    "Rank: 6        Logit: 11.39 Prob:  2.09% Token: | 5|\n",
    "Top 0th token. Logit: 11.95 Prob:  3.67% Token: | 1|\n",
    "Performance on answer token:\n",
    "Rank: 27       Logit:  9.31 Prob:  0.51% Token: |79|\n",
    "Top 0th token. Logit: 12.48 Prob: 12.00% Token: |.|\n",
    "Ranks of the answer tokens: [(' 5', 6), ('79', 27)]\n",
    "\n",
    "\n",
    "prompt=|123+ 456 =|, answer=| 579|\n",
    "Tokenized prompt: ['<|endoftext|>', '123', '+', ' 4', '56', ' =']\n",
    "Tokenized answer: [' 5', '79']\n",
    "Performance on answer token:\n",
    "Rank: 5        Logit:  9.91 Prob:  1.63% Token: | 5|\n",
    "Top 0th token. Logit: 10.61 Prob:  3.29% Token: | 1|\n",
    "Performance on answer token:\n",
    "Rank: 80       Logit:  8.25 Prob:  0.26% Token: |79|\n",
    "Top 0th token. Logit: 11.77 Prob:  8.72% Token: |.|\n",
    "Ranks of the answer tokens: [(' 5', 5), ('79', 80)]\n",
    "```\n",
    "\n",
    "* first output token logit diff from answer token logit = `|11.39 - 11.95| = -0.56`\n",
    "* second output token logit diff from answer token logit = `|9.31 - 12.48| = -3.17`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_wrong_answer_tokens=tensor([[642, 352]], device='mps:0')\n",
      "Answer residual directions shape: torch.Size([1, 2, 768])\n",
      "logit_diff_directions.shape=torch.Size([1, 768])\n",
      "answer_residual_directions[0,0,0]=tensor(-0.1862, device='mps:0')\n",
      "logit for token | 5|: output_logit0[0, -1, 642]=tensor(11.3875, device='mps:0')\n",
      "logit for token | 1|: output_logit0[0, -1, 352]=tensor(11.9513, device='mps:0')\n",
      "logit for token |79|: output_logit1[0, -1, 3720]=tensor(9.3148, device='mps:0')\n",
      "scaled_final_token_residual_stream.shape=torch.Size([1, 768])\n",
      "scaled_final_token_residual_stream[0,0]=tensor(0.1353, device='mps:0')\n",
      "cache0[\"ln_final.hook_normalized\"].shape=torch.Size([1, 6, 768])\n",
      "cache0[\"ln_final.hook_normalized\"][0,-1,0]=tensor(0.1353, device='mps:0')\n",
      "calculated_logit_diff.shape=torch.Size([1, 50257])\n",
      "calculated_logit_diff[0,642]=tensor(11.3875, device='mps:0')\n",
      "answer_logits=tensor([[11.3875, 11.9513]], device='mps:0')\n",
      "Per prompt logit difference: tensor([-0.5640])\n"
     ]
    }
   ],
   "source": [
    "correct_wrong_answer_tokens = model.to_tokens(\n",
    "    \" 5 1\", prepend_bos=False).to(DEVICE)\n",
    "print(f'{correct_wrong_answer_tokens=}')\n",
    "answer_residual_directions = model.tokens_to_residual_directions(\n",
    "    correct_wrong_answer_tokens)\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "# logit_diff_directions = (\n",
    "#     # token | 5| - token | 1|\n",
    "#     answer_residual_directions[:, 0] - answer_residual_directions[:, 1]\n",
    "# )\n",
    "print(f'{logit_diff_directions.shape=}')\n",
    "print(f'{answer_residual_directions[0,0,0]=}')\n",
    "# logit_diff_directions = (\n",
    "#     answer_residual_directions[:, 0] - answer_residual_directions[:, 1]\n",
    "# )\n",
    "# print(\"Logit difference directions shape:\", logit_diff_directions.shape)\n",
    "\n",
    "# 768 refers to the dimensionality of the embedding and hidden states within the model\n",
    "\n",
    "# cache syntax - resid_post is the residual stream at the end of the layer, -1 gets the final layer.\n",
    "# The general syntax is [activation_name, layer_index, sub_layer_type].\n",
    "input_tokens0 = model.to_tokens(\"123 + 456 =\", prepend_bos=True)\n",
    "output_logit0, cache0 = model.run_with_cache(input_tokens0)\n",
    "print(f'logit for token | 5|: {output_logit0[0, -1, 642]=}')\n",
    "print(f'logit for token | 1|: {output_logit0[0, -1, 352]=}')\n",
    "assert (torch.eq(output_logit0[0, -1, 642].round(decimals=4), 11.3875).item())\n",
    "\n",
    "input_tokens1 = model.to_tokens(\n",
    "    \"123 + 456 = 5\", prepend_bos=True)  # advance 1 more token\n",
    "output_logit1, cache1 = model.run_with_cache(input_tokens1)\n",
    "print(f'logit for token |79|: {output_logit1[0, -1, 3720]=}')\n",
    "assert (torch.eq(output_logit1[0, -1, 3720].round(decimals=4), 9.3148).item())\n",
    "\n",
    "final_residual_stream0 = cache0[\"resid_post\", -1]  # shape [1, 6, 768]\n",
    "final_token_residual_stream = final_residual_stream0[:, -1, :]\n",
    "# Apply LayerNorm scaling\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache0.apply_ln_to_stack(\n",
    "    final_token_residual_stream, layer=-1, pos_slice=-1\n",
    ")\n",
    "print(f'{scaled_final_token_residual_stream.shape=}')\n",
    "print(f'{scaled_final_token_residual_stream[0,0]=}')\n",
    "print(f'{cache0[\"ln_final.hook_normalized\"].shape=}')\n",
    "print(f'{cache0[\"ln_final.hook_normalized\"][0,-1,0]=}')\n",
    "\n",
    "calculated_logit_diff = cache0[\"ln_final.hook_normalized\"][:, -1, :]\n",
    "calculated_logit_diff = calculated_logit_diff @ model.unembed.W_U + model.unembed.b_U\n",
    "print(f'{calculated_logit_diff.shape=}')\n",
    "print(f'{calculated_logit_diff[0,642]=}')\n",
    "\n",
    "\n",
    "def logits_to_ave_logit_diff(logits, answer_tokens):\n",
    "    # Only the final logits are relevant for the answer\n",
    "    final_logits = logits[:, -1, :]\n",
    "    answer_logits = final_logits.gather(dim=-1, index=answer_tokens)\n",
    "    print(f'{answer_logits=}')\n",
    "    return answer_logits[:, 0] - answer_logits[:, 1]\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Per prompt logit difference:\",\n",
    "    logits_to_ave_logit_diff(output_logit0, correct_wrong_answer_tokens)\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .round(decimals=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" 123456754234 + 84729123475\"\n",
    "tokens = model.to_tokens(text)\n",
    "logits, activations = model.run_with_cache(tokens, remove_batch_dim=True)\n",
    "attention_pattern = activations[\"pattern\", 0, \"attn\"]\n",
    "str_tokens = model.to_str_tokens(text)\n",
    "cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(tokens, return_type='loss')\n",
    "print(f'{loss=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_ablate = 0\n",
    "head_index_to_ablate = 1\n",
    "\n",
    "\n",
    "def head_ablation_hook(value, hook):\n",
    "    print(f\"Shape of the value tensor: {value.shape} {hook}\")\n",
    "    value[:, :, 1, :] = 0.\n",
    "    value[:, :, 2, :] = 0.\n",
    "    return value\n",
    "\n",
    "\n",
    "activations = None\n",
    "with model.hooks(fwd_hooks=[(utils.get_act_name(\"attn\", 0, \"pattern\"), head_ablation_hook)]):\n",
    "    print(model)\n",
    "    logits, activations = model.run_with_cache(tokens, remove_batch_dim=True)\n",
    "    loss = model(tokens, return_type='loss')\n",
    "    print(f'{loss=}')\n",
    "\n",
    "attention_pattern = activations[\"pattern\", 0, \"attn\"]\n",
    "cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern)\n",
    "\n",
    "# loss = model.run_with_hooks(\n",
    "#     tokens,\n",
    "#     return_type='loss',\n",
    "#     fwd_hooks=[(\n",
    "#         utils.get_act_name(\"v\", layer_to_ablate),\n",
    "#         head_ablation_hook\n",
    "#     )]\n",
    "# )\n",
    "# cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prompt = \"After John and Mary went to the store, Mary gave a bottle of milk to\"\n",
    "corrupted_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "# clean_prompt = \"The Space Needle is in the city of\"\n",
    "# corrupted_prompt = \"Eiffel Tower is located in the city of\"\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
    "\n",
    "def logits_to_logit_diff(logits, correct_answer, incorrect_answer):\n",
    "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
    "    # If the string is not a single token, it raises an error.\n",
    "    correct_index = model.to_single_token(correct_answer)\n",
    "    incorrect_index = model.to_single_token(incorrect_answer)\n",
    "    # print(f'{correct_index=}, {incorrect_index=}')\n",
    "    # print(f'{logits.shape=}')\n",
    "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
    "\n",
    "# We run on the clean prompt with the cache so we store activations to patch in later.\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = logits_to_logit_diff(clean_logits, correct_answer=\" Seattle\", incorrect_answer=\" Paris\")\n",
    "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
    "\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits, correct_answer=\" Paris\", incorrect_answer=\" Seattle\")\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")\n",
    "\n",
    "# str_tokens = model.to_str_tokens(clean_prompt)\n",
    "# print(clean_cache)\n",
    "# attention_pattern = clean_cache[\"pattern\", 0, \"attn\"]\n",
    "# cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a residual stream patching hook\n",
    "# We choose to act on the residual stream at the start of the layer, so we call it resid_pre\n",
    "# The type annotations are a guide to the reader and are not necessary\n",
    "def residual_stream_patching_hook(resid_pre, hook, position):\n",
    "    # Each HookPoint has a name attribute giving the name of the hook.\n",
    "    clean_resid_pre = clean_cache[hook.name]\n",
    "    resid_pre[:, position, :] = clean_resid_pre[:, position, :]\n",
    "    return resid_pre\n",
    "\n",
    "\n",
    "# We make a tensor to store the results for each patching run. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "print(f'{clean_tokens.shape=}')\n",
    "num_positions = len(clean_tokens[0])\n",
    "print(f'{num_positions=}')\n",
    "ioi_patching_result = torch.zeros(\n",
    "    (model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
    "\n",
    "for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
    "    for position in range(num_positions):\n",
    "        # Use functools.partial to create a temporary hook function with the position fixed\n",
    "        temp_hook_fn = partial(\n",
    "            residual_stream_patching_hook, position=position)\n",
    "        # Run the model with the patching hook\n",
    "        patched_logits = model.run_with_hooks(corrupted_tokens, fwd_hooks=[\n",
    "            (utils.get_act_name(\"resid_pre\", layer), temp_hook_fn)\n",
    "        ])\n",
    "        # Calculate the logit difference\n",
    "        patched_logit_diff = logits_to_logit_diff(patched_logits, correct_answer=\" Seattle\", incorrect_answer=\" Paris\").detach()\n",
    "        # Store the result, normalizing by the clean and corrupted logit difference so it's between 0 and 1 (ish)\n",
    "        ioi_patching_result[layer, position] = (\n",
    "            patched_logit_diff - corrupted_logit_diff)/(clean_logit_diff - corrupted_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the index to the end of the label, because plotly doesn't like duplicate labels\n",
    "token_labels = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(clean_tokens))]\n",
    "imshow(ioi_patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "seq_len = 50\n",
    "size = (batch_size, seq_len)\n",
    "input_tensor = torch.randint(0, 10000, size)\n",
    "\n",
    "random_tokens = input_tensor.to(model.cfg.device)\n",
    "repeated_tokens = einops.repeat(random_tokens, \"batch seq_len -> batch (2 seq_len)\")\n",
    "repeated_logits = model(repeated_tokens)\n",
    "correct_log_probs = model.loss_fn(repeated_logits, repeated_tokens, per_token=True)\n",
    "loss_by_position = einops.reduce(correct_log_probs, \"batch position -> position\", \"mean\")\n",
    "line(loss_by_position, xaxis=\"Position\", yaxis=\"Loss\", title=\"Loss by position on random repeated tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "induction_score_store = torch.zeros(\n",
    "    (model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
    "\n",
    "\n",
    "def induction_score_hook(pattern, hook):\n",
    "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
    "    # (This only has entries for tokens with index>=seq_len)\n",
    "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
    "    # Get an average score per head\n",
    "    induction_score = einops.reduce(\n",
    "        induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
    "    # Store the result.\n",
    "    induction_score_store[hook.layer(), :] = induction_score\n",
    "\n",
    "\n",
    "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
    "def pattern_hook_names_filter(name): return name.endswith(\"pattern\")\n",
    "\n",
    "\n",
    "model.run_with_hooks(\n",
    "    repeated_tokens,\n",
    "    return_type=None,  # For efficiency, we don't need to calculate the logits\n",
    "    fwd_hooks=[(\n",
    "        pattern_hook_names_filter,\n",
    "        induction_score_hook\n",
    "    )]\n",
    ")\n",
    "\n",
    "imshow(induction_score_store, xaxis=\"Head\",\n",
    "       yaxis=\"Layer\", title=\"Induction Score by Head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "induction_head_layer = 18\n",
    "induction_head_index = 5\n",
    "size = (1, 20)\n",
    "input_tensor = torch.randint(1000, 10000, size)\n",
    "\n",
    "single_random_sequence = input_tensor.to(model.cfg.device)\n",
    "repeated_random_sequence = einops.repeat(single_random_sequence, \"batch seq_len -> batch (2 seq_len)\")\n",
    "def visualize_pattern_hook(pattern, hook):\n",
    "    display(\n",
    "        cv.attention.attention_patterns(\n",
    "            tokens=model.to_str_tokens(repeated_random_sequence), \n",
    "            attention=pattern[0, induction_head_index, :, :][None, :, :] # Add a dummy axis, as CircuitsVis expects 3D patterns.\n",
    "        )\n",
    "    )\n",
    "\n",
    "model.run_with_hooks(\n",
    "    repeated_random_sequence, \n",
    "    return_type=None, \n",
    "    fwd_hooks=[(\n",
    "        utils.get_act_name(\"pattern\", induction_head_layer), \n",
    "        visualize_pattern_hook\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"The quick brown fox jumped over the lazy dog\"\n",
    "print(\"Num tokens:\", len(model.to_tokens(test_prompt)[0]))\n",
    "\n",
    "def print_name_shape_hook_function(activation, hook):\n",
    "    print(hook.name, activation.shape)\n",
    "\n",
    "not_in_late_block_filter = lambda name: name.startswith(\"blocks.0.\") or not name.startswith(\"blocks\")\n",
    "\n",
    "model.run_with_hooks(\n",
    "    test_prompt,\n",
    "    return_type=None,\n",
    "    fwd_hooks=[(not_in_late_block_filter, print_name_shape_hook_function)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"1111 + 2222 =\"\n",
    "example_answer = \" 3333\"\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
